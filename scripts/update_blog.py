#!/usr/bin/env python3


import feedparser
import re
import os
import subprocess
import urllib.parse
from datetime import datetime
from typing import List, Dict

BLOG_RSS_URL = "https://cry4o4n0tfound.cn/atom.xml"
BOOKMARK_RSS_URL = "https://bookmark.cry4o4n0tfound.cc/feeds/shared"
README_PATH = "README.md"
MAX_POSTS = 5

def fetch_latest_posts() -> List[Dict]:
    """Fetch latest blog posts from RSS feed"""
    try:
        feed = feedparser.parse(BLOG_RSS_URL)
        posts = []
        
        for entry in feed.entries[:MAX_POSTS]:
            # è§£æå‘å¸ƒæ—¥æœŸï¼Œä¼˜å…ˆä½¿ç”¨updatedå­—æ®µ
            date_parsed = entry.get('updated_parsed') or entry.get('published_parsed')
            if date_parsed:
                date_str = datetime(*date_parsed[:6]).strftime('%Y-%m-%d')
            else:
                date_str = "Unknown"
            
            # æ­£ç¡®ç¼–ç URLï¼Œå¤„ç†ç©ºæ ¼ç­‰ç‰¹æ®Šå­—ç¬¦
            raw_link = entry.get('link', '#')
            # åªå¯¹URLä¸­éœ€è¦ç¼–ç çš„éƒ¨åˆ†è¿›è¡Œç¼–ç ï¼Œé¿å…åŒé‡ç¼–ç 
            if ' ' in raw_link or any(char in raw_link for char in ['[', ']', '(', ')']):
                encoded_link = urllib.parse.quote(raw_link, safe=':/?#@!$&\'*+,;=')
            else:
                encoded_link = raw_link
            
            posts.append({
                'title': entry.get('title', 'Untitled'),
                'link': encoded_link,
                'date': date_str
            })
        
        return posts
    except Exception as e:
        print(f"Error fetching blog RSS feed: {e}")
        return []

def fetch_latest_bookmarks() -> List[Dict]:
    """Fetch latest bookmarks from RSS feed"""
    try:
        # ä½¿ç”¨curlå‘½ä»¤è·å–RSSå†…å®¹ï¼Œé¿å…SSLé—®é¢˜
        result = subprocess.run(
            ['curl', '-k', '-s', BOOKMARK_RSS_URL],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        if result.returncode != 0:
            print(f"Error fetching bookmark RSS feed: {result.stderr}")
            return []
        
        # è§£æRSSå†…å®¹
        feed = feedparser.parse(result.stdout)
        bookmarks = []
        
        for entry in feed.entries[:MAX_POSTS]:
            # è§£æå‘å¸ƒæ—¥æœŸ
            published = entry.get('published_parsed')
            if published:
                date_str = datetime(*published[:6]).strftime('%Y-%m-%d')
            else:
                date_str = "Unknown"
            
            # æ­£ç¡®ç¼–ç URLï¼Œå¤„ç†ç©ºæ ¼ç­‰ç‰¹æ®Šå­—ç¬¦
            raw_link = entry.get('link', '#')
            # åªå¯¹URLä¸­éœ€è¦ç¼–ç çš„éƒ¨åˆ†è¿›è¡Œç¼–ç ï¼Œé¿å…åŒé‡ç¼–ç 
            if ' ' in raw_link or any(char in raw_link for char in ['[', ']', '(', ')']):
                encoded_link = urllib.parse.quote(raw_link, safe=':/?#@!$&\'*+,;=')
            else:
                encoded_link = raw_link
            
            bookmarks.append({
                'title': entry.get('title', 'Untitled'),
                'link': encoded_link,
                'date': date_str
            })
        
        return bookmarks
    except Exception as e:
        print(f"Error fetching bookmark RSS feed: {e}")
        return []

def update_readme(posts: List[Dict], bookmarks: List[Dict]):
    """Update README.md with latest blog posts and bookmarks"""
    if not posts and not bookmarks:
        print("No posts or bookmarks to update")
        return
    
    # è¯»å–å½“å‰ README å†…å®¹
    with open(README_PATH, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # åˆ›å»ºåšå®¢éƒ¨åˆ†
    blog_section = ""
    if posts:
        blog_section = "## Latest Blog Posts\n\n"
        blog_section += f"*Auto-updated from [cry4o4n0tfound.cn](https://cry4o4n0tfound.cn)*\n\n"
        
        for post in posts:
            # æ¸…ç†æ ‡é¢˜ä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼Œé¿å…Markdownè§£æé—®é¢˜
            clean_title = post['title'].replace('[', '\\[').replace(']', '\\]')
            blog_section += f"- [{clean_title}]({post['link']}) - {post['date']}\n"
        blog_section += "\n"
    
    # åˆ›å»ºä¹¦ç­¾éƒ¨åˆ†
    bookmark_section = ""
    if bookmarks:
        bookmark_section = "## Recent Bookmarks\n\n"
        bookmark_section += f"*Auto-updated from [bookmark.cry4o4n0tfound.cc](https://bookmark.cry4o4n0tfound.cc)*\n\n"
        
        for bookmark in bookmarks:
            # æ¸…ç†æ ‡é¢˜ä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼Œé¿å…Markdownè§£æé—®é¢˜
            clean_title = bookmark['title'].replace('[', '\\[').replace(']', '\\]')
            bookmark_section += f"- [{clean_title}]({bookmark['link']}) - {bookmark['date']}\n"
        bookmark_section += "\n"
    
    # åˆå¹¶ä¸¤ä¸ªéƒ¨åˆ†
    combined_section = blog_section + bookmark_section
    
    # æŸ¥æ‰¾å¹¶æ›¿æ¢å†…å®¹éƒ¨åˆ†
    # åˆ†åˆ«å¤„ç†åšå®¢å’Œä¹¦ç­¾éƒ¨åˆ†ï¼Œé¿å…ä¸€ä¸ªå¤±è´¥å½±å“å¦ä¸€ä¸ª
    blog_pattern = r'## Latest Blog Posts.*?(?=## Recent Bookmarks|## Tech Stack|## GitHub Stats|$)'
    bookmark_pattern = r'## Recent Bookmarks.*?(?=## Tech Stack|## GitHub Stats|$)'
    
    new_content = content
    
    # æ›´æ–°åšå®¢éƒ¨åˆ†
    if posts:
        if re.search(blog_pattern, new_content, re.DOTALL):
            new_content = re.sub(blog_pattern, blog_section.strip() + '\n\n', new_content, flags=re.DOTALL)
        else:
            # å¦‚æœä¸å­˜åœ¨åšå®¢éƒ¨åˆ†ï¼Œåœ¨ä¸ªäººä»‹ç»åæ·»åŠ 
            intro_pattern = r'(And I have a blog, you can learn more about me from here ğŸ‘‰ \[cry4o4n0tfound\.cn\]\(https://cry4o4n0tfound\.cn\)\.\n\n)'
            if re.search(intro_pattern, new_content, re.DOTALL):
                new_content = re.sub(intro_pattern, r'\1' + blog_section, new_content)
            else:
                new_content = new_content + '\n\n' + blog_section
    
    # æ›´æ–°ä¹¦ç­¾éƒ¨åˆ†
    if bookmarks:
        if re.search(bookmark_pattern, new_content, re.DOTALL):
            new_content = re.sub(bookmark_pattern, bookmark_section.strip() + '\n\n', new_content, flags=re.DOTALL)
        else:
            # å¦‚æœä¸å­˜åœ¨ä¹¦ç­¾éƒ¨åˆ†ï¼Œåœ¨åšå®¢éƒ¨åˆ†åæ·»åŠ 
            if posts:
                new_content = new_content.replace(blog_section.strip(), blog_section.strip() + '\n\n' + bookmark_section.strip())
            else:
                new_content = new_content + '\n\n' + bookmark_section
    
    # å†™å…¥æ›´æ–°åçš„å†…å®¹
    with open(README_PATH, 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    print(f"Updated README with {len(posts)} blog posts and {len(bookmarks)} bookmarks")

def main():
    """Main function"""
    print("Fetching latest blog posts...")
    posts = fetch_latest_posts()
    
    print("Fetching latest bookmarks...")
    bookmarks = fetch_latest_bookmarks()
    
    if posts:
        print(f"Found {len(posts)} blog posts:")
        for post in posts:
            print(f"  - {post['title']} ({post['date']})")
    
    if bookmarks:
        print(f"Found {len(bookmarks)} bookmarks:")
        for bookmark in bookmarks:
            print(f"  - {bookmark['title']} ({bookmark['date']})")
    
    if posts or bookmarks:
        update_readme(posts, bookmarks)
        print("README updated successfully!")
    else:
        print("No posts or bookmarks found or error occurred")

if __name__ == "__main__":
    main()
